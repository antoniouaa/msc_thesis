\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {UKenglish}{}
\babel@toc {UKenglish}{}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.1}{\ignorespaces Graphical representation of a Neuron\relax }}{3}{figure.caption.4}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Plot of the Rectified Linear Unit function, generated using Python\relax }}{4}{figure.caption.5}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Plot of the sigmoid function, generated using Python\relax }}{5}{figure.caption.6}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Plot of the hyperbolic tangent function, generated using Python\relax }}{6}{figure.caption.7}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Matrix representation of the Jacobian matrix\textsuperscript {\cite {jacobian_img}} $\mathbf {J}$ of function $\mathbf {f}$. Every entry $(i, j)$ in the matrix is $\mathbf {J}_{i, j} = \frac {\partial f_i}{\partial x_j}$\relax }}{7}{figure.caption.8}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.6}{\ignorespaces Diagram of the LSTM cell\textsuperscript {\cite {lstm_cell}}\relax }}{8}{figure.caption.9}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.1}{\ignorespaces Autocorrelation function before any differencing, generated using Python\relax }}{12}{figure.caption.10}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.2}{\ignorespaces PACF and ACF of differenced series, generated using Python\relax }}{13}{figure.caption.11}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Walk Forward Validation of ARIMA model using the \texttt {statsmodels} library\relax }}{14}{figure.caption.12}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Model Architecture, generated using \LaTeX \relax }}{14}{figure.caption.13}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Description of layers, generated using Python\relax }}{16}{figure.caption.15}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Comparison of MAE (blue) and MSE (orange). Note how MAE scales linearly with higher error values while MSE scales quadratically, treating higher errors more harshly.\relax }}{17}{figure.caption.16}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5.1}{\ignorespaces Simple normalisation of data using \texttt {MinMaxScaler} from the \texttt {sklearn} library\relax }}{19}{figure.caption.18}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5.2}{\ignorespaces Splitting of data into features and labels\relax }}{20}{figure.caption.19}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
