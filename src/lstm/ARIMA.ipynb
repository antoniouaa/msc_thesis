{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                          date   close     high       low    open    volume  \\\n0     2016-01-04T00:00:00.000Z  105.35  105.368  102.0000  102.61  67649387   \n1     2016-01-05T00:00:00.000Z  102.71  105.850  102.4100  105.75  55790992   \n2     2016-01-06T00:00:00.000Z  100.70  102.370   99.8700  100.56  68457388   \n3     2016-01-07T00:00:00.000Z   96.45  100.130   96.4300   98.68  81094428   \n4     2016-01-08T00:00:00.000Z   96.96   99.110   96.7600   98.55  70798016   \n...                        ...     ...      ...       ...     ...       ...   \n1001  2019-12-24T00:00:00.000Z  284.27  284.890  282.9197  284.69  12119714   \n1002  2019-12-26T00:00:00.000Z  289.91  289.980  284.7000  284.82  23334004   \n1003  2019-12-27T00:00:00.000Z  289.80  293.970  288.1200  291.12  36592936   \n1004  2019-12-30T00:00:00.000Z  291.52  292.690  285.2200  289.46  36059614   \n1005  2019-12-31T00:00:00.000Z  293.65  293.680  289.5200  289.93  25247625   \n\n        adjClose     adjHigh      adjLow     adjOpen  adjVolume  divCash  \\\n0      97.940352   97.957086   94.825970   95.393066   67649387      0.0   \n1      95.486033   98.405185   95.207133   98.312219   55790992      0.0   \n2      93.617403   95.169946   92.845780   93.487250   68457388      0.0   \n3      89.666321   93.087494   89.647728   91.739477   81094428      0.0   \n4      90.140451   92.139234   89.954518   91.618621   70798016      0.0   \n...          ...         ...         ...         ...        ...      ...   \n1001  282.839838  283.456719  281.496331  283.257725   12119714      0.0   \n1002  288.451463  288.521111  283.267674  283.387071   23334004      0.0   \n1003  288.342016  292.491037  286.670468  289.655375   36592936      0.0   \n1004  290.053363  291.217477  283.785058  288.003727   36059614      0.0   \n1005  292.172647  292.202496  288.063425  288.471362   25247625      0.0   \n\n      splitFactor  \n0             1.0  \n1             1.0  \n2             1.0  \n3             1.0  \n4             1.0  \n...           ...  \n1001          1.0  \n1002          1.0  \n1003          1.0  \n1004          1.0  \n1005          1.0  \n\n[1006 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>close</th>\n      <th>high</th>\n      <th>low</th>\n      <th>open</th>\n      <th>volume</th>\n      <th>adjClose</th>\n      <th>adjHigh</th>\n      <th>adjLow</th>\n      <th>adjOpen</th>\n      <th>adjVolume</th>\n      <th>divCash</th>\n      <th>splitFactor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-04T00:00:00.000Z</td>\n      <td>105.35</td>\n      <td>105.368</td>\n      <td>102.0000</td>\n      <td>102.61</td>\n      <td>67649387</td>\n      <td>97.940352</td>\n      <td>97.957086</td>\n      <td>94.825970</td>\n      <td>95.393066</td>\n      <td>67649387</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-05T00:00:00.000Z</td>\n      <td>102.71</td>\n      <td>105.850</td>\n      <td>102.4100</td>\n      <td>105.75</td>\n      <td>55790992</td>\n      <td>95.486033</td>\n      <td>98.405185</td>\n      <td>95.207133</td>\n      <td>98.312219</td>\n      <td>55790992</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-06T00:00:00.000Z</td>\n      <td>100.70</td>\n      <td>102.370</td>\n      <td>99.8700</td>\n      <td>100.56</td>\n      <td>68457388</td>\n      <td>93.617403</td>\n      <td>95.169946</td>\n      <td>92.845780</td>\n      <td>93.487250</td>\n      <td>68457388</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-07T00:00:00.000Z</td>\n      <td>96.45</td>\n      <td>100.130</td>\n      <td>96.4300</td>\n      <td>98.68</td>\n      <td>81094428</td>\n      <td>89.666321</td>\n      <td>93.087494</td>\n      <td>89.647728</td>\n      <td>91.739477</td>\n      <td>81094428</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-08T00:00:00.000Z</td>\n      <td>96.96</td>\n      <td>99.110</td>\n      <td>96.7600</td>\n      <td>98.55</td>\n      <td>70798016</td>\n      <td>90.140451</td>\n      <td>92.139234</td>\n      <td>89.954518</td>\n      <td>91.618621</td>\n      <td>70798016</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>2019-12-24T00:00:00.000Z</td>\n      <td>284.27</td>\n      <td>284.890</td>\n      <td>282.9197</td>\n      <td>284.69</td>\n      <td>12119714</td>\n      <td>282.839838</td>\n      <td>283.456719</td>\n      <td>281.496331</td>\n      <td>283.257725</td>\n      <td>12119714</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>2019-12-26T00:00:00.000Z</td>\n      <td>289.91</td>\n      <td>289.980</td>\n      <td>284.7000</td>\n      <td>284.82</td>\n      <td>23334004</td>\n      <td>288.451463</td>\n      <td>288.521111</td>\n      <td>283.267674</td>\n      <td>283.387071</td>\n      <td>23334004</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>2019-12-27T00:00:00.000Z</td>\n      <td>289.80</td>\n      <td>293.970</td>\n      <td>288.1200</td>\n      <td>291.12</td>\n      <td>36592936</td>\n      <td>288.342016</td>\n      <td>292.491037</td>\n      <td>286.670468</td>\n      <td>289.655375</td>\n      <td>36592936</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>2019-12-30T00:00:00.000Z</td>\n      <td>291.52</td>\n      <td>292.690</td>\n      <td>285.2200</td>\n      <td>289.46</td>\n      <td>36059614</td>\n      <td>290.053363</td>\n      <td>291.217477</td>\n      <td>283.785058</td>\n      <td>288.003727</td>\n      <td>36059614</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>2019-12-31T00:00:00.000Z</td>\n      <td>293.65</td>\n      <td>293.680</td>\n      <td>289.5200</td>\n      <td>289.93</td>\n      <td>25247625</td>\n      <td>292.172647</td>\n      <td>292.202496</td>\n      <td>288.063425</td>\n      <td>288.471362</td>\n      <td>25247625</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1006 rows Ã— 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "from statsmodels.tsa.arima_model import ARIMA \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "TICKER_DIR = \"C:\\\\Users\\\\anton\\\\Documents\\\\antoniouaa\\\\msc_thesis\\\\data\\\\tickers\\\\ticker_data\"\n",
    "\n",
    "dataset = pd.read_csv(os.path.join(TICKER_DIR, \"AAPL.csv\"))\n",
    "dataset = dataset.dropna(how=\"any\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_arima(X, order):\n",
    "    size = int(len(X) * 0.6)\n",
    "    train, test = X[:size], X[size:]\n",
    "    history = [x for x in train]\n",
    "    predictions = []\n",
    "    # perform walk-forward validation\n",
    "    for t in range(len(test)):\n",
    "        # fit arima model to the history of values\n",
    "        model = ARIMA(history, order=order)\n",
    "        model_fit = model.fit(disp=-1)\n",
    "        # predict the next value\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_models(X, p_values, d_values, q_values):\n",
    "    scores = []\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p, d, q)\n",
    "                try:\n",
    "                    mse = evaluate_arima(X, order)\n",
    "                    scores.append((mse, order))\n",
    "                    print(f\"ARIMA ORDER: {order}\\tMSE: {mse}\")\n",
    "                except:\n",
    "                    continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ARIMA ORDER: (0, 0, 0)\tMSE: 3821.8814001182213\nARIMA ORDER: (0, 0, 1)\tMSE: 1033.7350948344583\nARIMA ORDER: (0, 1, 0)\tMSE: 11.734324374072088\nARIMA ORDER: (0, 1, 1)\tMSE: 11.815273785838126\nARIMA ORDER: (0, 1, 2)\tMSE: 11.798110453292773\nARIMA ORDER: (0, 2, 0)\tMSE: 23.82513037931285\nARIMA ORDER: (0, 2, 1)\tMSE: 11.796213936505604\nARIMA ORDER: (0, 2, 2)\tMSE: 11.888266339347307\nARIMA ORDER: (1, 0, 0)\tMSE: 11.817900605795554\nARIMA ORDER: (1, 1, 0)\tMSE: 11.810913253059034\nARIMA ORDER: (1, 1, 1)\tMSE: 11.892296187819516\nARIMA ORDER: (1, 2, 0)\tMSE: 18.653292474651664\nARIMA ORDER: (1, 2, 1)\tMSE: 11.880698118481483\nARIMA ORDER: (1, 2, 2)\tMSE: 11.841949775738277\nARIMA ORDER: (2, 0, 0)\tMSE: 11.943224546804979\nARIMA ORDER: (2, 1, 0)\tMSE: 11.79766354031549\nARIMA ORDER: (2, 1, 1)\tMSE: 11.791101446322925\nARIMA ORDER: (2, 1, 2)\tMSE: 12.041865524239054\nARIMA ORDER: (2, 2, 0)\tMSE: 16.561400234927344\nARIMA ORDER: (2, 2, 1)\tMSE: 11.861757302275702\nARIMA ORDER: (2, 2, 2)\tMSE: 11.943216025427253\nARIMA ORDER: (4, 0, 0)\tMSE: 11.92928856211048\nARIMA ORDER: (4, 1, 0)\tMSE: 11.880810882486308\nARIMA ORDER: (4, 1, 1)\tMSE: 11.83622076363368\nARIMA ORDER: (4, 1, 2)\tMSE: 12.147233556536124\nARIMA ORDER: (4, 2, 0)\tMSE: 14.219498121390117\nARIMA ORDER: (4, 2, 1)\tMSE: 11.947399035267212\nARIMA ORDER: (4, 2, 2)\tMSE: 12.008601420170235\nARIMA ORDER: (6, 0, 0)\tMSE: 12.011551200051223\nARIMA ORDER: (6, 1, 0)\tMSE: 11.985144621017012\nARIMA ORDER: (6, 1, 1)\tMSE: 12.08785496160058\nARIMA ORDER: (6, 1, 2)\tMSE: 12.072673453906557\nARIMA ORDER: (6, 2, 0)\tMSE: 12.954496092871793\nARIMA ORDER: (6, 2, 2)\tMSE: 12.112976865114527\nBEST SCORE: (0, 1, 0)\tORDER: 11.734324374072088\n"
    }
   ],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "warnings.simplefilter(\"ignore\", HessianInversionWarning)\n",
    "\n",
    "X = dataset[\"close\"].values\n",
    "scores = evaluate_models(X, [0, 1, 2, 4, 6], range(3), range(3))\n",
    "best_score = sorted(scores)[0]\n",
    "print(f\"BEST SCORE: {best_score[1]}\\tORDER: {best_score[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try a prediction with the optimal ARIMA parameters\n",
    "X = dataset[\"close\"].values\n",
    "model = ARIMA(X, (4, 1, 2))\n",
    "model_ = model.fit(disp=False)\n",
    "yhat = model_.forecast()[0]\n",
    "print(f\"Current Value: {X[-1]}\\nForecast: {yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# two step forecast\n",
    "forecasting = model_.forecast(steps=5)\n",
    "forecast_vals = forecasting[0]\n",
    "# reshape the arrays to have the same length\n",
    "preds = np.zeros(len(X)+len(forecast_vals))\n",
    "preds[-len(forecast_vals):] = forecast_vals\n",
    "preds[preds==0] = np.NaN\n",
    "# plot them on top of each other\n",
    "plt.plot(X)\n",
    "plt.plot(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(os.path.join(TICKER_DIR, \"MA_BAP.csv\"))\n",
    "test_set = test_set.dropna(how=\"any\")\n",
    "test_X = test_set[\"close\"].values\n",
    "scores = evaluate_models(test_X, [0, 1, 2, 4, 6], range(3), range(3))\n",
    "best_score = sorted(scores)[0]\n",
    "print(f\"BEST SCORE: {best_score[1]}\\tORDER: {best_score[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.41735308],\n       [0.42277325],\n       [0.42311468],\n       ...,\n       [0.06845632],\n       [0.06773078],\n       [0.06794418]])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Unify all data and normalize them to [0, 1]\n",
    "# Then perform grid search to find the optimal ARIMA hyperparameters\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TICKER_DIR = \"C:\\\\Users\\\\anton\\\\Documents\\\\antoniouaa\\\\msc_thesis\\\\data\\\\tickers\\\\ticker_data\\\\_Rolling\"\n",
    "tickers = []\n",
    "os.getcwd()\n",
    "cols = [\"close\"]\n",
    "for tick in os.listdir(TICKER_DIR):\n",
    "    path = os.path.join(TICKER_DIR, tick)\n",
    "    tick_df = pd.read_csv(path, header=0, usecols=cols, squeeze=True)\n",
    "    tickers.append(tick_df)\n",
    "\n",
    "df = pd.concat(tickers)\n",
    "X = df.values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ARIMA ORDER: (0, 0, 0)\tMSE: 0.026282427501433427\nARIMA ORDER: (0, 0, 1)\tMSE: 0.0076512836084998296\nARIMA ORDER: (0, 1, 0)\tMSE: 0.0003019037547837042\nARIMA ORDER: (0, 1, 1)\tMSE: 0.00030193748483150297\nARIMA ORDER: (0, 1, 2)\tMSE: 0.0003019847439414797\nARIMA ORDER: (0, 2, 0)\tMSE: 0.0006024538250254549\nARIMA ORDER: (0, 2, 1)\tMSE: 0.00030210259710299677\nARIMA ORDER: (0, 2, 2)\tMSE: 0.0003024305351752679\nARIMA ORDER: (1, 0, 0)\tMSE: 0.00030115859104032697\nARIMA ORDER: (1, 0, 1)\tMSE: 0.0003011833907391868\nARIMA ORDER: (1, 0, 2)\tMSE: 0.00030123177428806086\nARIMA ORDER: (1, 1, 0)\tMSE: 0.000301939417601608\nARIMA ORDER: (1, 2, 0)\tMSE: 0.0004606290157417548\nARIMA ORDER: (1, 2, 1)\tMSE: 0.000302133480945515\nARIMA ORDER: (1, 2, 2)\tMSE: 0.00030236192926837765\nARIMA ORDER: (2, 0, 0)\tMSE: 0.00030118579173162333\nARIMA ORDER: (2, 1, 0)\tMSE: 0.0003019846697362073\nARIMA ORDER: (2, 2, 0)\tMSE: 0.00041057501490515637\nARIMA ORDER: (2, 2, 1)\tMSE: 0.00030260409230600945\nARIMA ORDER: (2, 2, 2)\tMSE: 0.0003023464064197741\nARIMA ORDER: (4, 0, 0)\tMSE: 0.0003012352052404922\nARIMA ORDER: (4, 1, 0)\tMSE: 0.0003019743287139355\nARIMA ORDER: (4, 2, 0)\tMSE: 0.0003689425466144486\nARIMA ORDER: (4, 2, 1)\tMSE: 0.00030265747471015954\nARIMA ORDER: (4, 2, 2)\tMSE: 0.0003026624381565505\nARIMA ORDER: (6, 0, 0)\tMSE: 0.0003012422314784881\nARIMA ORDER: (6, 0, 1)\tMSE: 0.00030123683921421936\nARIMA ORDER: (6, 0, 2)\tMSE: 0.0003012689763417817\nARIMA ORDER: (6, 1, 0)\tMSE: 0.0003019933108282785\nARIMA ORDER: (6, 2, 0)\tMSE: 0.00034930106794044054\nARIMA ORDER: (6, 2, 1)\tMSE: 0.00030275745993810975\nARIMA ORDER: (6, 2, 2)\tMSE: 0.0003025152850783301\n"
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "warnings.simplefilter(\"ignore\", HessianInversionWarning)\n",
    "\n",
    "possible_orders = ((0, 1, 2, 4, 6), (0, 1, 2), (0, 1, 2))\n",
    "scores = evaluate_models(scaled_df, [0, 1, 2, 4, 6], range(3), range(3))\n",
    "# evaluate_arima(scaled_df, (0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'scaled_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3e678cee3fb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Current Value: {X[-1]}\\nForecast: {yhat}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_df' is not defined"
     ]
    }
   ],
   "source": [
    "a_order = (2, 0, 0)\n",
    "model = ARIMA(scaled_df, a_order)\n",
    "model_ = model.fit(disp=False)\n",
    "yhat = model_.forecast()[0]\n",
    "print(f\"Current Value: {X[-1]}\\nForecast: {yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitvenvvenv61f31972c6ca4ba6a42a1aafdf3b0bc0",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}